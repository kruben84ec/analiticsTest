
"""
Métodos predictivos

"""
# Cambiamos la variable categórica CODE_GENDER por la variable numérica CODE_GENDER (Donde male = 1, fremale = 0)
applicationDF = pd.get_dummies(applicationDF, columns=['CODE_GENDER'], drop_first=True)



# print(categorize_data.head())
# # Seleccionamos las características para el modelo

data = applicationDF[['NAME_CONTRACT_TYPE_', 'GENDER_','AGE',"NAME_EDUCATION_TYPE_", "CNT_CHILDREN" , 'NAME_FAMILY_STATUS_','TARGET']]
# data = applicationDF[['NAME_CONTRACT_TYPE_', 'GENDER_','AGE',"NAME_EDUCATION_TYPE_",'TARGET']]


# print(data.head())
# X son nuestras variables independientes
X_independent = data.drop(["TARGET"],axis = 1)
# y es nuestra variable dependiente
y_dependet = data.TARGET

# # División 75% de datos para entrenamiento, 25% de daatos para test
# X_train, X_test, y_train, y_test = train_test_split(X_independent, y_dependet,random_state=0)
# # División 60% de datos para entrenamiento, 40% de daatos para test
X_train, X_test, y_train, y_test = train_test_split(X_independent, y_dependet,test_size=0.25, random_state=0)


# # Creaamos el modelo de Bosques Aleatorios (y configuramos el número de estimadores (árboles de decisión))
BA_model = RandomForestClassifier(n_estimators = 30, 
                                  random_state = 0,
                                  min_samples_leaf = 100,)
# """
# Entrenamiento 
# """
BA_model.fit(X_train, y_train)
# # Accuracy promedio
# acurrancy_meave= BA_model.score(X_test, y_test)
# print('RandomForestClassifier: ', acurrancy_meave)

from sklearn.ensemble import GradientBoostingRegressor
model = GradientBoostingRegressor(random_state=0).fit(X_train, y_train)
# acurrancy_meave=model.score(X_train, y_train)
# print('GradientBoostingRegressor: ', acurrancy_meave)

from sklearn.neural_network import MLPClassifier
from sklearn.neural_network import MLPRegressor
# Import necessary modules
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.metrics import r2_score

target_column = ['TARGET'] 
predictors = list(set(list(data.columns))-set(target_column))
data[predictors] = data[predictors]/data[predictors].max()
X_independent = data[predictors].values
y = data[target_column].values

X_train, X_test, y_train, y_test = train_test_split(X_independent, y, test_size=0.30, random_state=40)


from sklearn.neural_network import MLPClassifier

mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)
mlp.fit(X_train,y_train)

predict_train = mlp.predict(X_train)
predict_test = mlp.predict(X_test)


from sklearn.metrics import classification_report,confusion_matrix
# print(confusion_matrix(y_train,predict_train))
# print(classification_report(y_train,predict_train))

# print(confusion_matrix(y_test,predict_test))
# print(classification_report(y_test,predict_test))

# time_process = round((time.time() - start_time),2)
# print('Giskard: Tiempo que se demoro en ejecutar', time_process, "Segundos")